{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "In the following code, we will gather information on each article. The information we are obtaining is the school (Stanford or Berkeley), the url, the date the article was published, the headline of the article, and the content of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11', '20', '2017']\n",
      "['11', '20', '2017']\n",
      "['11', '17', '2017']\n",
      "['11', '15', '2017']\n",
      "['11', '14', '2017']\n",
      "['11', '14', '2017']\n",
      "['11', '13', '2017']\n",
      "['11', '08', '2017']\n",
      "['11', '08', '2017']\n",
      "['11', '07', '2017']\n",
      "['11', '03', '2017']\n",
      "['11', '02', '2017']\n",
      "['10', '26', '2017']\n",
      "['10', '24', '2017']\n",
      "['10', '16', '2017']\n",
      "['10', '09', '2017']\n",
      "['10', '08', '2017']\n",
      "['10', '06', '2017']\n",
      "['09', '29', '2017']\n",
      "['09', '29', '2017']\n",
      "['09', '26', '2017']\n",
      "['09', '14', '2017']\n",
      "['09', '14', '2017']\n",
      "['09', '08', '2017']\n",
      "['09', '06', '2017']\n",
      "['07', '11', '2017']\n",
      "['06', '27', '2017']\n",
      "['06', '21', '2017']\n",
      "['06', '20', '2017']\n",
      "['06', '11', '2017']\n",
      "['06', '07', '2017']\n",
      "['06', '02', '2017']\n",
      "['06', '01', '2017']\n",
      "['05', '31', '2017']\n",
      "['05', '25', '2017']\n",
      "['05', '24', '2017']\n",
      "['05', '22', '2017']\n",
      "['05', '17', '2017']\n",
      "['05', '09', '2017']\n",
      "['05', '09', '2017']\n",
      "['05', '02', '2017']\n",
      "['04', '14', '2017']\n",
      "['04', '03', '2017']\n",
      "['03', '14', '2017']\n",
      "['03', '13', '2017']\n",
      "['03', '07', '2017']\n",
      "['03', '05', '2017']\n",
      "['03', '03', '2017']\n",
      "['03', '01', '2017']\n",
      "['02', '28', '2017']\n",
      "['02', '28', '2017']\n",
      "['02', '27', '2017']\n",
      "['02', '23', '2017']\n",
      "['02', '13', '2017']\n",
      "['02', '07', '2017']\n",
      "['02', '03', '2017']\n",
      "['02', '03', '2017']\n",
      "['02', '03', '2017']\n",
      "['02', '02', '2017']\n",
      "['02', '02', '2017']\n",
      "['02', '01', '2017']\n",
      "['02', '01', '2017']\n",
      "['01', '31', '2017']\n",
      "['01', '31', '2017']\n",
      "['01', '30', '2017']\n",
      "['01', '30', '2017']\n",
      "['01', '25', '2017']\n",
      "['01', '20', '2017']\n",
      "['01', '17', '2017']\n",
      "['01', '16', '2017']\n",
      "['01', '05', '2017']\n",
      "\n",
      "\n",
      "['11', '14', '2017']\n",
      "['11', '07', '2017']\n",
      "['11', '03', '2017']\n",
      "['10', '31', '2017']\n",
      "['10', '27', '2017']\n",
      "['10', '24', '2017']\n",
      "['10', '20', '2017']\n",
      "['10', '17', '2017']\n",
      "['10', '13', '2017']\n",
      "['10', '10', '2017']\n",
      "['10', '10', '2017']\n",
      "['10', '06', '2017']\n",
      "['09', '29', '2017']\n",
      "['09', '26', '2017']\n",
      "['09', '26', '2017']\n",
      "['09', '22', '2017']\n",
      "['09', '19', '2017']\n",
      "['09', '15', '2017']\n",
      "['09', '11', '2017']\n",
      "['09', '07', '2017']\n",
      "['09', '05', '2017']\n",
      "['09', '01', '2017']\n",
      "['09', '01', '2017']\n",
      "['08', '29', '2017']\n",
      "['08', '29', '2017']\n",
      "['08', '25', '2017']\n",
      "['08', '22', '2017']\n",
      "['08', '22', '2017']\n",
      "['08', '14', '2017']\n",
      "['08', '07', '2017']\n",
      "['07', '31', '2017']\n",
      "['07', '24', '2017']\n",
      "['07', '17', '2017']\n",
      "['07', '10', '2017']\n",
      "['07', '03', '2017']\n",
      "['06', '26', '2017']\n",
      "['06', '19', '2017']\n",
      "['06', '12', '2017']\n",
      "['06', '05', '2017']\n",
      "['06', '05', '2017']\n",
      "['05', '30', '2017']\n",
      "['05', '22', '2017']\n",
      "['05', '15', '2017']\n",
      "['05', '08', '2017']\n",
      "['05', '01', '2017']\n",
      "['04', '28', '2017']\n",
      "['04', '25', '2017']\n",
      "['04', '21', '2017']\n",
      "['04', '18', '2017']\n",
      "['04', '10', '2017']\n",
      "['04', '10', '2017']\n",
      "['04', '10', '2017']\n",
      "['04', '10', '2017']\n",
      "['04', '07', '2017']\n",
      "['04', '07', '2017']\n",
      "['04', '07', '2017']\n",
      "['04', '07', '2017']\n",
      "['04', '07', '2017']\n",
      "['04', '07', '2017']\n",
      "['04', '03', '2017']\n",
      "['03', '24', '2017']\n",
      "['03', '21', '2017']\n",
      "['03', '17', '2017']\n",
      "['03', '14', '2017']\n",
      "['03', '10', '2017']\n",
      "['03', '07', '2017']\n",
      "['03', '03', '2017']\n",
      "['02', '28', '2017']\n",
      "['02', '24', '2017']\n",
      "['02', '21', '2017']\n",
      "['02', '17', '2017']\n",
      "['02', '14', '2017']\n",
      "['02', '10', '2017']\n",
      "['02', '07', '2017']\n",
      "['02', '03', '2017']\n",
      "['01', '31', '2017']\n",
      "['01', '27', '2017']\n",
      "['01', '24', '2017']\n",
      "['01', '24', '2017']\n",
      "['01', '20', '2017']\n",
      "['01', '17', '2017']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/daily_cal_corpus.txt\") as f:\n",
    "    dailyc = f.read()\n",
    "    \n",
    "with open(\"data/stanford-daily-corpus.txt\") as f:\n",
    "    sdaily = f.read()\n",
    "\n",
    "calarticles = dailyc.split(\"\\n\\n\\n\")\n",
    "stanarticles = sdaily.split(\"\\n\\n\\n\")\n",
    "\n",
    "def create_metadata(article_lst, school):\n",
    "    i = 1\n",
    "    all_info = []\n",
    "    for article in article_lst:\n",
    "        article = article.strip().split(\"\\n\")\n",
    "        url  = \"Error\"\n",
    "        headline = \"Error\"\n",
    "        content = \"\"\n",
    "        for index in range(len(article)):\n",
    "            if index == 0:\n",
    "                url = article[index]\n",
    "            elif index == 1:\n",
    "                headline = article[index]\n",
    "            else:\n",
    "                content = content + article[index]\n",
    "        if school == 'Stanford Daily':\n",
    "            url = url[8:]\n",
    "        if school == 'Daily Cal':\n",
    "            url = url[7:]\n",
    "        splitted = url.split('/')\n",
    "        date = [splitted[2], splitted[3], splitted[1]]\n",
    "        print(date)\n",
    "        information = [school, url, date, headline, content]\n",
    "        all_info.append(information)\n",
    "    return all_info\n",
    "        \n",
    "        \n",
    "stanford = create_metadata(stanarticles, 'Stanford Daily')\n",
    "print()\n",
    "print()\n",
    "cal = create_metadata(calarticles, 'Daily Cal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Publication</th> <th>Link</th> <th>Date</th> <th>Headline</th> <th>Content</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/11/14/alta-bates-planned-closure-p ...</td> <td>['11' '14' '2017']</td> <td>Alta Bates planned closure puts Berkeley residents at risk  </td> <td>CITY AFFAIRS: Community members have mobilized recently  ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/11/07/berkeley-community-fight-stay/  </td> <td>['11' '07' '2017']</td> <td>Berkeley community here to fight, here to stay              </td> <td>NATIONAL ISSUES: A look at Berkeley one year after the N ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/11/03/berkeley-mayor-must-explicit ...</td> <td>['11' '03' '2017']</td> <td>Berkeley mayor must explicitly call out racial disparity ...</td> <td>CITY AFFAIRS: City Council punted on two major Berkeley  ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/10/31/event-policy-draft-use-impro ...</td> <td>['10' '31' '2017']</td> <td>Event policy draft could use improvement                    </td> <td>CAMPUS ISSUES: Student organizations may suffer the cons ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/10/27/history-visual-propaganda-no ...</td> <td>['10' '27' '2017']</td> <td>History of visual propaganda, stereotypes should not be  ...</td> <td>CAMPUS ISSUES: A recent editorial cartoon stoked valid c ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/10/24/current-climate-new-vice-cha ...</td> <td>['10' '24' '2017']</td> <td>In current climate, new vice chancellor of equity and in ...</td> <td>CAMPUS ISSUES: Oscar Dubón, Jr. will need a clearer visi ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/10/20/new-law-aiming-restrict-uc-c ...</td> <td>['10' '20' '2017']</td> <td>New law aiming to restrict UC campuses from giving enrol ...</td> <td>UNIVERSITY ISSUES: California lawmakers should not waste ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/10/17/berkeley-far-ready-next-big- ...</td> <td>['10' '17' '2017']</td> <td>Berkeley far from ready for next big hills fire             </td> <td>CITY AFFAIRS: As California grapples with wildfire month ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/10/13/asuc-cannot-neglect-sexual-v ...</td> <td>['10' '13' '2017']</td> <td>ASUC cannot neglect sexual violence prevention commission   </td> <td>CAMPUS ISSUES: The ASUC Senate is supposed to approve th ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Daily Cal  </td> <td>www.dailycal.org/2017/10/10/new-university-wisconsin-pol ...</td> <td>['10' '10' '2017']</td> <td>New University of Wisconsin policy hypocritically exploi ...</td> <td>NATIONAL ISSUES: The new policy comes amid a perceived \" ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (142 rows omitted)</p"
      ],
      "text/plain": [
       "Publication | Link                                                         | Date               | Headline                                                     | Content\n",
       "Daily Cal   | www.dailycal.org/2017/11/14/alta-bates-planned-closure-p ... | ['11' '14' '2017'] | Alta Bates planned closure puts Berkeley residents at risk   | CITY AFFAIRS: Community members have mobilized recently  ...\n",
       "Daily Cal   | www.dailycal.org/2017/11/07/berkeley-community-fight-stay/   | ['11' '07' '2017'] | Berkeley community here to fight, here to stay               | NATIONAL ISSUES: A look at Berkeley one year after the N ...\n",
       "Daily Cal   | www.dailycal.org/2017/11/03/berkeley-mayor-must-explicit ... | ['11' '03' '2017'] | Berkeley mayor must explicitly call out racial disparity ... | CITY AFFAIRS: City Council punted on two major Berkeley  ...\n",
       "Daily Cal   | www.dailycal.org/2017/10/31/event-policy-draft-use-impro ... | ['10' '31' '2017'] | Event policy draft could use improvement                     | CAMPUS ISSUES: Student organizations may suffer the cons ...\n",
       "Daily Cal   | www.dailycal.org/2017/10/27/history-visual-propaganda-no ... | ['10' '27' '2017'] | History of visual propaganda, stereotypes should not be  ... | CAMPUS ISSUES: A recent editorial cartoon stoked valid c ...\n",
       "Daily Cal   | www.dailycal.org/2017/10/24/current-climate-new-vice-cha ... | ['10' '24' '2017'] | In current climate, new vice chancellor of equity and in ... | CAMPUS ISSUES: Oscar Dubón, Jr. will need a clearer visi ...\n",
       "Daily Cal   | www.dailycal.org/2017/10/20/new-law-aiming-restrict-uc-c ... | ['10' '20' '2017'] | New law aiming to restrict UC campuses from giving enrol ... | UNIVERSITY ISSUES: California lawmakers should not waste ...\n",
       "Daily Cal   | www.dailycal.org/2017/10/17/berkeley-far-ready-next-big- ... | ['10' '17' '2017'] | Berkeley far from ready for next big hills fire              | CITY AFFAIRS: As California grapples with wildfire month ...\n",
       "Daily Cal   | www.dailycal.org/2017/10/13/asuc-cannot-neglect-sexual-v ... | ['10' '13' '2017'] | ASUC cannot neglect sexual violence prevention commission    | CAMPUS ISSUES: The ASUC Senate is supposed to approve th ...\n",
       "Daily Cal   | www.dailycal.org/2017/10/10/new-university-wisconsin-pol ... | ['10' '10' '2017'] | New University of Wisconsin policy hypocritically exploi ... | NATIONAL ISSUES: The new policy comes amid a perceived \" ...\n",
       "... (142 rows omitted)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_table(all_info):\n",
    "    publication = make_array()\n",
    "    links = make_array()\n",
    "    dates = []\n",
    "    headlines = make_array()\n",
    "    content = make_array()\n",
    "    for article in all_info:\n",
    "        publication = np.append(publication, article[0])\n",
    "        links = np.append(links, article[1])\n",
    "        dates.append(article[2])\n",
    "        headlines = np.append(headlines, article[3])\n",
    "        content = np.append(content, article[4])\n",
    "    return Table().with_columns('Publication', publication,\n",
    "                               'Link', links, 'Date', dates,\n",
    "                               'Headline', headlines, 'Content', content)\n",
    "\n",
    "info_table = create_table(cal + stanford)\n",
    "info_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification \n",
    "\n",
    "Now that we have a table composed of the article content and the publication it was published for, we can begin to test whether there is a difference. The way we are looking to do this is through classification. We will train our model on half of the table, telling which content maps with which publication. Then, we will use that model to test the other half and see how our model does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = info_table.column('Content')\n",
    "publication = info_table.column('Publication')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we have an array of content and an array of their corresponding publication. Now we would like to see if the publication has any dependency on the publication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "x, y = shuffle(content, publication, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('By any objective standard, my career as an NCAA Division I athlete was unremarkable. An undersized walk-on defensive end to the Stanford Cardinal in the fall of 2004, I toiled on the practice squad for three years before breaking a few bones and deciding to move on with my life. When I made the hard decision to quit, I went to see our coach, Jim Harbaugh. He listened to my reasons and then, as though I were weighing the pros and cons of playing for the first time, said, “You know, football builds character.”He was right.Football had a huge impact on my life. An only child, it gave me a sense of belonging. A husky kid — \\u200ato use a charitable term coined by Levi’s Jeans and lovingly employed by my mother — \\u200ait made me feel valuable for my large size.I began to play the game when I was 12 years old. It scared me at first. It was violent and left no room for excuses. As a player, you quickly learn that hesitation and weakness will be punished. Eleven players mutually responsible for one another’s well-being — a momentary lapse of resolve can lead to loss or injury.When I got to Stanford, the identity of being a football player was comfortable and reinforcing. I loved the unity and camaraderie on the team. We competed against one another constantly, but it was the healthy kind of competition: the kind that makes you sharper.Politics were often present in the locker room, and there was a wide range of views. Though the student body leaned to the left, the team was more conservative than the campus. I remember debates about the war in Iraq with my teammates. Many players came from military families, and the mentality of the sport bore resemblance to service. Of my four roommates in college, two went on to become Navy SEALs. They continue to serve today, and I’m proud to call them my friends.My wife, a psychiatrist, sometimes struggles to understand what motivated me to ritualistically slam my head into the heads of other young men for nearly a decade. Certainly, there was a pursuit of glory and a hope to realize individual greatness. I think it also appealed to an innate sense of purpose I felt representing my school and protecting my teammates.When Coach Harbaugh said his memorable words to me, I was hurt and angry, but mostly I felt alone. I would never again stand shoulder-to-shoulder with my friends as we tried to achieve something together. Yearning for that feeling of belonging again, I began to volunteer for Barack Obama’s presidential campaign and ultimately joined as a member of his campaign staff.The campaign felt familiar — it was full of fiercely loyal people, giving themselves to a cause, striving to win. But as I organized communities from Iowa to New Mexico during the unfolding financial crisis, I began to experience a sense of purpose I hadn’t experienced before. It wasn’t a game. The campaign was breaking down centuries of barriers, and the outcome of the election would dramatically affect peoples’ lives.Years later, I found myself working in the West Wing of the White House as a special assistant to the Chief of Staff. I had many important responsibilities, including getting coffee and lunch for senior White House staff and unjamming the copy machine that had seemingly been there since the Carter Administration.Even menial tasks in the White House seem to carry disproportionate meaning. I began every morning by collecting the President’s daily briefing from the White House Situation Room. I held it closely in my arms, knowing the contents could save or risk lives. I thought about my grandfather, whose service as a naval officer in World War II was the proudest achievement of his 93 years. My service did not require daily bravery, but I was proud to serve nonetheless.I’ll admit, when I first saw Colin Kaepernick kneel in protest during the national anthem, I felt uncomfortable. I thought about the pride I’d felt as a player, standing with my hand over my heart before games; I thought about my roommates in the SEALs and my grandfather. The murders of unarmed civilians at the hands of police were indescribably horrible, but was the anthem the venue to protest?I now realize the ignorance of that question.Two Sundays have passed since the President chose to single out this form of protest. The statements made by players since then have been courageous and important. Black players and white players have knelt during the anthem, and many others have demonstrated solidarity in their own ways. These players have risked their reputations to send a jarring message that the status quo is not good enough.When the President told the players to stand, more knelt. Through that act of civil disobedience, they’ve contributed to a larger movement. The protests have extended to other sports and off the field. In the now-famous photo taken by Jonathan Ernst of Reuters, Marvin Boatright showed his patriotism through protest and said of his fellow veterans: “We love this country. We love this flag. But we also love life and liberty for all humanity.”As we saw with the Women’s March, protest works. It brings us together, raises important questions and exposes courage and cowardice. Through protest, we see the failings of our political system and our leaders.Football may be a game and a form of entertainment, but its players are strong, patriotic Americans. The game has taught them courage and what it means to stand for something larger than themselves. Though I’ll never again stand (or kneel) among them, their actions over these past weeks have made me proud to have ever considered myself a member of their ranks.Now it’s our turn to show character.As Martin Luther King Jr. knew when he relentlessly pressed President Johnson to pass the Voting Rights and Civil Rights Acts, protest and civil disobedience create righteous energy. That energy needs to be channeled through our democracy to make enduring change. The only way to correct the fundamental unfairness that rots at the core of our political system is to mobilize to support strong candidates who will fight to protect the rights of all Americans.',\n",
       " 'Stanford Daily')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96875     0.96666667  0.96666667  0.96666667  0.96666667] 0.967083333333\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression(random_state=0, penalty='l2', C=1000))\n",
    "                     ])\n",
    "\n",
    "scores = cross_val_score(text_clf, x, y, cv=5)\n",
    "\n",
    "print(scores, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# get tfidf values\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "x_train = tfidf.transform(x_train)\n",
    "x_test = tfidf.transform(x_test)\n",
    "\n",
    "# build and test logit\n",
    "logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    "model = logit_class.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Our model scored pretty high. But before getting too excited, we decided to check, what were common feature names that our model used to distinguish between Berkeley and Stanford articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features for Stanford reviews:\n",
      "['paris', 'edith', 'theme', 'you', 'we', 'in', 'that', 'our', 'me', 'is', 'of', 'american', 'agreement', 'postdocs', 'indigenous', 'path', 'dgen', 'my', 'and', 'stanford']\n",
      "\n",
      "Top features for Berkeley reviews:\n",
      "['berkeley', 'uc', 'campus', 'opinion', 'city', 'students', 'asuc', 'chancellor', 'board', 'editorial', 'state', 'editor', 'yiannopoulos', 'pride', 'represent', 'christ', 'written', 'cal', 'majority', 'editorials']\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "top20stanford = np.argsort(model.coef_[0])[-20:]\n",
    "print(\"Top features for Stanford reviews:\")\n",
    "print(list(feature_names[j] for j in top20stanford))\n",
    "print()\n",
    "print(\"Top features for Berkeley reviews:\")\n",
    "top20cal = np.argsort(model.coef_[0])[:20]\n",
    "print(list(feature_names[j] for j in top20cal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top feature for Stanford reviews:\n",
      "['stanford']\n",
      "\n",
      "Top feature for Berkeley reviews:\n",
      "['berkeley']\n"
     ]
    }
   ],
   "source": [
    "topstanford = np.argsort(model.coef_[0])[-1:]\n",
    "print(\"Top feature for Stanford reviews:\")\n",
    "print(list(feature_names[j] for j in topstanford))\n",
    "print()\n",
    "print(\"Top feature for Berkeley reviews:\")\n",
    "topcal = np.argsort(model.coef_[0])[:1]\n",
    "print(list(feature_names[j] for j in topcal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the classifier's most prominent distinguisher between Daily Cal and Stanford Daily articles is \"berkeley\" and \"stanford\". Well, that feels like cheating! We decided to replace \"berkeley\" and \"stanford\" with \"college\" to test our model more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_model(con, pub): \n",
    "    np.random.seed(1)\n",
    "    x, y = shuffle(con, pub, random_state=0)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
    "\n",
    "    # get tfidf values\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit(x)\n",
    "    x_train = tfidf.transform(x_train)\n",
    "    x_test = tfidf.transform(x_test)\n",
    "\n",
    "    # build and test logit\n",
    "    logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    "    model = logit_class.fit(x_train, y_train)\n",
    "    feature_names = tfidf.get_feature_names()\n",
    "    top20stanford = np.argsort(model.coef_[0])[-20:]\n",
    "    \n",
    "    print(\"Top features for Stanford reviews:\")\n",
    "    print(list(feature_names[j] for j in top20stanford))\n",
    "    print()\n",
    "    print(\"Top features for Berkeley reviews:\")\n",
    "    top20cal = np.argsort(model.coef_[0])[:20]\n",
    "    print(list(feature_names[j] for j in top20cal))\n",
    "    \n",
    "    return model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_word(arr, old, new):\n",
    "    new_arr = make_array()\n",
    "    for elem in arr:\n",
    "        new_arr = np.append(new_arr, elem.lower().replace(old, new))\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = replace_word(content, 'berkeley', 'college')\n",
    "content = replace_word(content, 'stanford', 'college')\n",
    "content = replace_word(content, 'uc', '') #also replacing 'UC' which is associated with 'UC' Berkeley\n",
    "content = replace_word(content, 'cal', 'college')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features for Stanford reviews:\n",
      "['workers', 'these', 'you', 'american', 'our', 'agreement', 'football', 'is', 'díaz', 'me', 'spencer', 'we', 'indigenous', 'of', 'postdocs', 'dgen', 'that', 'path', 'my', 'and']\n",
      "\n",
      "Top features for Berkeley reviews:\n",
      "['campus', 'opinion', 'city', 'students', 'chancellor', 'board', 'yiannopoulos', 'editorial', 'state', 'christ', 'editor', 'represent', 'written', 'editorials', 'majority', 'police', 'as', 'candidates', 'homeless', 'pride']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90322580645161288"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_model(content, publication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even by replacing 'berkeley', 'stanford', 'cal', and 'uc', our model scores very high! This gives us reason to believe that the content Daily Cal covers v. the content Stanford Daily covers is quite different. In the next steps, we will explore how the content is different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
